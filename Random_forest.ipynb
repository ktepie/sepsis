{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer as imputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import glob\n",
    "from driver import stack_list, stack_labels, return_shapes, return_to_original, split_probs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "labels = []\n",
    "\n",
    "for f in sorted(glob.glob(\"training/\" + \"/*.psv\")):\n",
    "    df_list.append(pd.read_csv(f,sep='|'))\n",
    "    labels.append(df_list[len(df_list)-1][\"SepsisLabel\"])\n",
    "    \n",
    "\n",
    "#Making sure that imputation does not removes the EtC02 column\n",
    "#Also removing the sepsislable column from the original data\n",
    "for i in df_list:\n",
    "    i.iloc[0,i.columns.get_loc('EtCO2')] = 0\n",
    "    i.drop('SepsisLabel', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "df_list2 = []\n",
    "labels2 = []\n",
    "\n",
    "for f in sorted(glob.glob(\"training_setB/\" + \"/*.psv\")):\n",
    "    df_list2.append(pd.read_csv(f,sep='|'))\n",
    "    labels2.append(df_list2[len(df_list2)-1][\"SepsisLabel\"])\n",
    "    \n",
    "    \n",
    "for i in df_list2:\n",
    "    i.drop('SepsisLabel', axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(df_list,labels,test_size=0.4)\n",
    "x_train = df_list\n",
    "y_train = labels\n",
    "\n",
    "x_test = df_list2\n",
    "y_test = labels2\n",
    "\n",
    "#Getting the datas original shapes before stacking tjem\n",
    "train_shapes = return_shapes(x_train)\n",
    "test_shapes = return_shapes(x_test)\n",
    "\n",
    "#Normalizing and stacking the normalized data\n",
    "x_train = stack_list(x_train)\n",
    "x_train = (x_train-x_train.mean()) / x_train.std()\n",
    "x_test = stack_list(x_test)\n",
    "x_test = (x_test - x_test.mean()) / x_test.std()\n",
    "\n",
    "y_train = stack_labels(y_train)\n",
    "# y_test = stack_labels(y_test)\n",
    "\n",
    "\n",
    "# #Shuffling the train data for better randomized result\n",
    "# randomizer = np.random.permutation(len(x_train))\n",
    "# x_train = x_train[randomizer]\n",
    "# y_train = y_train[randomizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the length of the predicted_labels list: 20000\n",
      "This is the length of the predicted_probabilities list: 20000\n",
      "*************************************************************************************************\n",
      "This is the shape of predicted_labels for patient no 9543: (22,)\n",
      "This is the shape of predicted_probabilities for patient no 9543: (22,)\n",
      "And the real shape of this patient no 9543 is : 22\n"
     ]
    }
   ],
   "source": [
    "classifier = sklearn.ensemble.RandomForestClassifier(n_estimators=60)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "('Creating the model is done ! Now commencing to the prediction part...')\n",
    "predicted_labels = return_to_original(classifier.predict(x_test),test_shapes)\n",
    "probabilities = split_probs(return_to_original(classifier.predict_proba(x_test),test_shapes))\n",
    "# real_values = return_to_original(y_test, test_shapes)\n",
    "\n",
    "\n",
    "print('This is the length of the predicted_labels list: {}'.format(len(predicted_labels)))\n",
    "print('This is the length of the predicted_probabilities list: {}'.format(len(probabilities)))\n",
    "\n",
    "print('*************************************************************************************************')\n",
    "ran_val = np.random.randint(low=5, high= len(predicted_labels)-1)\n",
    "print('This is the shape of predicted_labels for patient no {}: {}'.format(ran_val,predicted_labels[ran_val].shape))\n",
    "print('This is the shape of predicted_probabilities for patient no {}: {}'.format(ran_val,probabilities[ran_val].shape))\n",
    "print('And the real shape of this patient no {} is : {}'.format(ran_val,test_shapes[ran_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761995\n",
      "20000\n",
      "(25,)\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = classifier.predict(x_test)\n",
    "result = []\n",
    "index = 0\n",
    "    \n",
    "for i,k in enumerate(test_shapes):\n",
    "    result.append(predicted_labels[index:index+k])\n",
    "    index += k\n",
    "    \n",
    "\n",
    "print(len(predicted_labels))\n",
    "print(len(result))\n",
    "print(result[1].shape)\n",
    "print(result[1])\n",
    "print(result[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773079\n",
      "751215\n",
      "**********************\n",
      "14666\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "# predicted_labels = classifier.predict(x_test)\n",
    "predicted_labels = result\n",
    "\n",
    "check_list(y_train)\n",
    "check_list(y_test)\n",
    "\n",
    "print('**********************')\n",
    "\n",
    "check_list(predicted_labels)\n",
    "check_list(real_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels[28])\n",
    "print(predicted_labels[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing files to a directory under predictions\n",
    "output_directory = \"predictions\"\n",
    "if os.path.exists(output_directory):\n",
    "    shutil.rmtree(output_directory)\n",
    "    os.mkdir(output_directory)\n",
    "else: \n",
    "    os.mkdir(output_directory)\n",
    "\n",
    "for i,f in enumerate(predicted_labels):\n",
    "    with open('predictions/p1%05d.psv' % i, 'w') as f:\n",
    "        f.write('PredictedProbability|PredictedLabel\\n')\n",
    "        for(s,l) in zip(probabilities[i],predicted_labels[i]):\n",
    "            f.write('%g|%d\\n' % (s,l))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_outcomes():\n",
    "    df_list = []\n",
    "    labels = []\n",
    "\n",
    "    for f in sorted(glob.glob(\"training/\" + \"/*.psv\")):\n",
    "        df_list.append(pd.read_csv(f,sep='|'))\n",
    "        labels.append(df_list[len(df_list)-1][\"SepsisLabel\"])\n",
    "\n",
    "\n",
    "    #Making sure that imputation does not removes the EtC02 column\n",
    "    #Also removing the sepsislable column from the original data\n",
    "    for i in df_list:\n",
    "        i.iloc[0,i.columns.get_loc('EtCO2')] = 0\n",
    "        i.drop('SepsisLabel', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    df_list2 = []\n",
    "    labels2 = []\n",
    "\n",
    "    for f in sorted(glob.glob(\"training_setB/\" + \"/*.psv\")):\n",
    "        df_list2.append(pd.read_csv(f,sep='|'))\n",
    "        labels2.append(df_list2[len(df_list2)-1][\"SepsisLabel\"])\n",
    "\n",
    "\n",
    "    for i in df_list2:\n",
    "        i.drop('SepsisLabel', axis=1 , inplace=True)\n",
    "\n",
    "\n",
    "    x_train = df_list\n",
    "    y_train = labels\n",
    "\n",
    "    x_test = df_list2\n",
    "    y_test = labels2\n",
    "\n",
    "    #Getting the datas original shapes before stacking tjem\n",
    "    train_shapes = return_shapes(x_train)\n",
    "    test_shapes = return_shapes(x_test)\n",
    "\n",
    "    #Normalizing and stacking the normalized data\n",
    "    x_train = stack_list(x_train)\n",
    "    x_train = (x_train-x_train.mean()) / x_train.std()\n",
    "    x_test = stack_list(x_test)\n",
    "    x_test = (x_test - x_test.mean()) / x_test.std()\n",
    "\n",
    "    y_train = stack_labels(y_train)\n",
    "    y_test = stack_labels(y_test)\n",
    "    \n",
    "    randomizer = np.random.permutation(len(x_train))\n",
    "    x_train = x_train[randomizer]\n",
    "    y_train = y_train[randomizer]\n",
    "\n",
    "    classifier = sklearn.ensemble.RandomForestClassifier(n_estimators=100)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "    #Checking the dimensions of the data, as well as returning them to their original shapes\n",
    "    predicted_labels = return_to_original(classifier.predict(x_test),test_shapes)\n",
    "    probabilities = split_probs(return_to_original(classifier.predict_proba(x_test),test_shapes))\n",
    "    real_values = return_to_original(y_test, test_shapes)\n",
    "\n",
    "    print('This is the length of the predicted_labels list: {}'.format(len(predicted_labels)))\n",
    "    print('This is the length of the predicted_probabilities list: {}'.format(len(probabilities)))\n",
    "\n",
    "    ran_val = np.random.randint(low=5, high= len(predicted_labels)-1)\n",
    "    print('This is the shape of predicted_labels for patient no {}: {}'.format(ran_val,predicted_labels[ran_val].shape))\n",
    "    print('This is the shape of predicted_probabilities for patient no {}: {}'.format(ran_val,probabilities[ran_val].shape))\n",
    "    print('And the real shape of this patient no {} is : {}'.format(ran_val,test_shapes[ran_val]))\n",
    "    \n",
    "    \n",
    "    #Writing files to a directory under predictions\n",
    "    output_directory = \"predictions\"\n",
    "    if os.path.exists(output_directory):\n",
    "        shutil.rmtree(output_directory)\n",
    "        os.mkdir(output_directory)\n",
    "    else: \n",
    "        os.mkdir(output_directory)\n",
    "\n",
    "    for i,f in enumerate(predicted_labels):\n",
    "        with open('predictions/p1%05d.psv' % i, 'w') as f:\n",
    "            f.write('PredictedProbability|PredictedLabel\\n')\n",
    "            for(s,l) in zip(probabilities[i],predicted_labels[i]):\n",
    "                f.write('%g|%d\\n' % (s,l))\n",
    "    \n",
    "    print('Done')\n",
    "    return predicted_labels, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the detection hour of the patient.\n",
    "def detection_hour(label, prediction):\n",
    "    if np.max(label) == 0 or np.max(prediction) == 0:\n",
    "        return 500\n",
    "    \n",
    "    real_time = np.argmax(label)\n",
    "    prediction_time = np.argmax(prediction)\n",
    "    \n",
    "    return prediction_time - real_time\n",
    "    \n",
    "#Checks how many 0's present in the current list.\n",
    "def check_list(list):\n",
    "    counter = 0\n",
    "    for i in list:\n",
    "        if np.max(i) == 0:\n",
    "            counter+= 1\n",
    "        \n",
    "    print(counter)\n",
    "    \n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
