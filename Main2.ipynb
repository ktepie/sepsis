{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.python.keras.layers import SimpleRNN, LSTM\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer as imputer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "labels = []\n",
    "\n",
    "for f in glob.glob(\"training/\" + \"/*.psv\"):\n",
    "    df_list.append(pd.read_csv(f,sep='|'))\n",
    "    labels.append(df_list[len(df_list)-1][\"SepsisLabel\"])\n",
    "    \n",
    "    \n",
    "\n",
    "for i in df_list:\n",
    "    i.drop('SepsisLabel', axis=1, inplace=True)\n",
    "    \n",
    "# This part will be used to get test data, however since there is a dimension problem\n",
    "# e.g. 1st patch is 39 after imputation and 2nd one is 40, we will work with this later on\n",
    "# x_test = []\n",
    "# y_test = []\n",
    "\n",
    "# for f in glob.glob(\"training_setB/\" + \"/*.psv\"):\n",
    "#     x_test.append(pd.read_csv(f,sep='|'))\n",
    "#     y_test.append(x_test[len(x_test)-1][\"SepsisLabel\"])\n",
    "    \n",
    "    \n",
    "# for i in x_test:\n",
    "#     i.drop('SepsisLabel', axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns an array where each patient has their final label.\n",
    "def convert_label(set_of_labels):\n",
    "    labels = []\n",
    "    \n",
    "    for i in set_of_labels:\n",
    "        labels.append(np.max(i))\n",
    "        \n",
    "    return np.array(labels)\n",
    "\n",
    "# #This function returns an mean of a list w.r.t. each column.\n",
    "# def get_mean(theList):\n",
    "#     result = []\n",
    "    \n",
    "#     for i in theList:\n",
    "#         for row in i.values:\n",
    "#             result.append(row)\n",
    "            \n",
    "#     result = np.array(result)\n",
    "#     result = np.nanmean(result.astype('float64'), axis=0)\n",
    "    \n",
    "#     for i in result:\n",
    "#         if np.isnan(i):\n",
    "#             #dosomething\n",
    "            \n",
    "#     return result\n",
    "\n",
    "\n",
    "# Mean imputer\n",
    "def impute_mean(theList):\n",
    "    shape = []\n",
    "    result = []\n",
    "    cur = 0\n",
    "    \n",
    "    for i in theList:\n",
    "        shape.append(i.shape[0])\n",
    "            \n",
    "    df = pd.concat(theList)\n",
    "    df.fillna(df.mean())\n",
    "    \n",
    "    for i in shape:\n",
    "        result.append(df.iloc[cur:cur+i,:])\n",
    "        cur += i\n",
    "    \n",
    "    return result\n",
    "\n",
    "# This functions checks if two lists has the same size and shape    \n",
    "def check_shape(list1, list2):\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len(list1)):\n",
    "        if list1[i].shape[0] != list2[i].shape[0]:\n",
    "            counter += 1\n",
    "                \n",
    "        \n",
    "    return True if counter == 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(impute_mean(df_list), dtype='float32',padding='post')\n",
    "y_train = pad_sequences(labels, dtype='float32',padding='post')\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train,y_train,test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 16)                3648      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 336)               5712      \n",
      "=================================================================\n",
      "Total params: 9,360\n",
      "Trainable params: 9,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = x_train.shape[1]\n",
    "input_dim = x_train.shape[2]\n",
    "\n",
    "output_size = x_train.shape[1]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(LSTM(32, input_shape=(336, 40)))\n",
    "model.add(LSTM(16, input_shape=(x_train.shape[-2:]), activation = 'relu'))\n",
    "model.add(Dense(336))    \n",
    "\n",
    "# model.add(Dense(336), activation = 'softmax')   \n",
    "\n",
    "# Compile the model ready for training\n",
    "model.compile('SGD', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12201 samples\n",
      "12201/12201 [==============================] - 18s 2ms/sample - loss: nan - accuracy: 0.9975\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = batch_size, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict_classes(x_test[0:2,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8135, 336)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 classified correctly\n",
      "1 classified incorrectly\n",
      "0.00% of test set classified correctly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "predicted_probability = model.predict(x_test)\n",
    "\n",
    "predicted_class = predicted_classes = model.predict_classes(x_test)\n",
    "\n",
    "correct_preds = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_preds = np.nonzero(predicted_classes != y_test)[0]\n",
    "print(\"{0} classified correctly\".format(len(correct_preds)))\n",
    "print(\"{0} classified incorrectly\".format(len(incorrect_preds)))\n",
    "print(\"{0:.2f}% of test set classified correctly\".format(len(correct_preds) / len(y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_before_sepsis(datalist, labels, target):\n",
    "    data = []\n",
    "    \n",
    "    for i in range(datalist.shape[0]):\n",
    "        if np.max(labels[i])==1:\n",
    "            index = np.argmax(np.array(labels[i]))\n",
    "            if (index-target)<0:\n",
    "                index = 1\n",
    "            else:\n",
    "                index = index - target\n",
    "            data.append(datalist[i,0:index,:])\n",
    "        else:\n",
    "            data.append(datalist[i,:,:])\n",
    "            \n",
    "            \n",
    "    return np.array(data)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xTest = split_before_sepsis(x_test,y_test,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_generator(lambda: xTest, tf.int32, output_shapes=[None])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tf.ragged.constant(xTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8135,)\n",
      "(6, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       ...,\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xTest.shape)\n",
    "print(xTest[9].shape)\n",
    "\n",
    "model.predict(pad_sequences(xTest, dtype='float32',padding='post'))\n",
    "\n",
    "# model.predict(np.array(xTest[9],dtype=np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(3):\n",
    "  multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
